{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Home Depot Decor Case\n",
    "Getting Started  |  Data Prep  |  Data Exploration  |  Preprocessing  |  Model Tuning  |  **Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../modules')\n",
    "\n",
    "# read in functions/modules\n",
    "from helpers import read_in_dataset, get_num_of_levels, flatten_categories\n",
    "import hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Recommender Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender: \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def create_similarity_matrix(self):\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T06:06:10.236238Z",
     "start_time": "2019-07-22T06:06:10.233555Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Define Hierarchy Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Hierarchy:\n",
    "    '''\n",
    "    Build parent, child dictionary\n",
    "    '''\n",
    "    self.prod_map=None\n",
    "\n",
    "    def __init__(self, data, num_levels):\n",
    "        '''\n",
    "        Keyword Arguments:\n",
    "        ------------------\n",
    "        * data - flattened pandas dataframe\n",
    "        * num_levels - number of product category levels\n",
    "        '''\n",
    "\n",
    "        self.data= data\n",
    "        self.num_levels = num_levels\n",
    "        self.level_cols = list(data.columns[-self.num_levels:])\n",
    "        self.was_fit=False\n",
    "\n",
    "\n",
    "    def fit_transform(self):\n",
    "        '''\n",
    "        Fit (Encode Nodes) and Transform (Categories to Ids in Dataframe)\n",
    "        '''\n",
    "        # get notes\n",
    "        self.nodes = list(pd.unique(self.data.iloc[:,-self.num_levels:].values.ravel()))\n",
    "\n",
    "        #encode nodes\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(self.nodes)\n",
    "\n",
    "        #save mapping\n",
    "        self.node2id = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        self.id2node = dict(zip(le.transform(le.classes_),le.classes_))\n",
    "\n",
    "        self.data_encoded = self.data\n",
    "\n",
    "        for col in self.level_cols:\n",
    "            self.data_encoded[col] = pd.Series(le.transform(self.data_encoded[col].to_list()))\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def get_mappings(self, map_direction='encode'):\n",
    "        '''\n",
    "        Get mapping for nodes and ids (and ids to nodes)\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        dictionary\n",
    "        '''\n",
    "\n",
    "        if map_direction == 'encode':\n",
    "            return self.node2id\n",
    "        elif map_direction == 'decode':\n",
    "            return self.id2node\n",
    "\n",
    "\n",
    "    def get_parent_child_dict(self):\n",
    "        '''\n",
    "        Construct encoded parent - child dictionary\n",
    "        (e.g. {2: [5,9,22]...})\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        dictionary\n",
    "        '''\n",
    "\n",
    "        # Function to group category levels with sliding window\n",
    "        def parent_child_dict(col_lst):\n",
    "            for i in range(len(col_lst)-1):\n",
    "                j=i+1\n",
    "                yield(self.data_encoded.groupby(col_lst[i])[col_lst[j]].apply(set).to_dict())\n",
    "\n",
    "        level_dicts = list(parent_child_dict(self.level_cols))\n",
    "\n",
    "        # Add dictionaries together\n",
    "        for i in range(1, len(level_dicts)):\n",
    "            level_dicts[0].update(level_dicts[i])\n",
    "\n",
    "        self.prod_map = level_dicts[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Class\n",
    "\n",
    "**Preprocess Data:**\n",
    "* Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to preprocess data\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        '''init Data class'''\n",
    "        self.data=None\n",
    "        \n",
    "    def load_data(self, dataset, data_folder='raw', data_type='csv', verbose=False):\n",
    "        '''Read in dataset (csv format) to pandas dataframe\n",
    "\n",
    "            Keyword Arguments:\n",
    "            ------------------\n",
    "            * dataset - string with dataset filename\n",
    "            * data_folder - string with either raw or processed\n",
    "            * verbose - True will print intormation about the dataset\n",
    "\n",
    "            Returns:\n",
    "            --------\n",
    "            a pandas dataframe\n",
    "        '''\n",
    "        if data_type == 'csv':\n",
    "            df = pd.read_csv('../data/{}/{}'.format(data_folder, dataset))\n",
    "        elif data_type == 'excel':\n",
    "            df = pd.read_excel('../data/{}/{}'.format(data_folder, dataset))\n",
    "        else:\n",
    "            raise ValueError('Invalid file format. Please specify \"excel\" or \"csv\".')\n",
    "\n",
    "        if verbose:\n",
    "            print('\\n{0:-^80}'.format(' Reading in the following dataset: {0}'.format(dataset)))\n",
    "            print(\"\\n Shape: {0} rows and {1} columns\".format(*df.shape))\n",
    "            print('\\n{0:-^80}\\n'.format(' It has the following columns '))\n",
    "            print(df.columns)\n",
    "            print('\\n{0:-^80}\\n'.format(' The first 5 rows look like this '))\n",
    "            print(df.head())\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def expand_columns(self, category_series, df=None, drop_col=None, sep='>'):\n",
    "        '''\n",
    "    Take in Series with categories in string format and flatten into columns\n",
    "\n",
    "     Keyword Arguments:\n",
    "    ------------------\n",
    "    * category_series - series with string of categories\n",
    "    * df - pandas dataframe\n",
    "    * drop_col - name of column with nested categories (string)\n",
    "    * sep - puncuation that separates categories\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    a pandas dataframe\n",
    "    '''\n",
    "        num_levels = category_series.str.split(sep).apply(len).max()\n",
    "\n",
    "        col_labels = ['L' + str(i) for i in range(1, num_levels+1)]\n",
    "\n",
    "\n",
    "        category_levels = pd.DataFrame(category_series.str.split(sep).values.tolist(), columns=col_labels)\n",
    "        category_levels.fillna(value=pd.np.nan, inplace=True)\n",
    "\n",
    "        if df is not None:\n",
    "            merged_df = pd.merge(df,category_levels, left_index=True, right_index=True).drop(drop_col, axis=1)\n",
    "\n",
    "            return merged_df\n",
    "        else:\n",
    "            return category_levels\n",
    "    \n",
    "    def preprocess_text():\n",
    "       \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and process_data = True\n",
    "get_columns = True\n",
    "run_rec_engine = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data into DataFrame and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_and_process_data:\n",
    "    # drop orders with few items, one-hot encode l3 category information, drop unnecessary columns, \n",
    "    # and consolidate unique orders into single records\n",
    "    data = Data()\n",
    "    data.load_data('test_data\\All Transations - 2 Weeks.txt', format='tsv')\n",
    "    data.drop_small_orders(order_col='order_number', min_order_size=20)\n",
    "    data.expand_columns(['l3'])  \n",
    "    data.drop_columns(['l1', 'l2', 'l3', 'sku', 'brand'])\n",
    "    data.consolidate_orders(order_col='order_number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_columns:\n",
    "    search_col = \n",
    "    prod_col = \n",
    "    category_col =  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Rec Engine and Generate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_rec_engine:\n",
    "    rec_engine = Recommender(data.data, user_col=user_col, item_cols=item_cols, cf_method='item', similarity='jaccard')\n",
    "    rec_engine.create_similarity_matrix()\n",
    "    rec_engine.score_users()\n",
    "    rec_engine.generate_recs()\n",
    "    rec_engine.save_recs()\n",
    "    rec_engine.print_recs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create Model Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Fit Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Score Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:thddecor]",
   "language": "python",
   "name": "conda-env-thddecor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
