{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Home Depot Decor Case\n",
    "\n",
    "Getting Started  |  Data Prep  |  Data Exploration  |  **Preprocessing**  |  Model Tuning  |  Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T04:51:02.999564Z",
     "start_time": "2019-07-17T04:51:02.992821Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import networkx as nx\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T04:44:43.743716Z",
     "start_time": "2019-07-17T04:44:43.739209Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import inspect\n",
    "sys.path.insert(0, '../modules')\n",
    "\n",
    "\n",
    "# now read in new functions\n",
    "from helpers import read_in_dataset, get_num_of_levels, flatten_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in product related data\n",
    "verbose_opt = False\n",
    "catalog = read_in_dataset('Decor_catalog.csv', verbose=verbose_opt)\n",
    "prod_desc = read_in_dataset('Product_name_description.csv', verbose=verbose_opt)\n",
    "prod_engagement = read_in_dataset('Product_engagement.csv', verbose=verbose_opt)\n",
    "\n",
    "# Read in search related data\n",
    "navigations = read_in_dataset('Visual_navigations.csv', verbose=verbose_opt)\n",
    "search_imp = read_in_dataset('Search_impression.csv', verbose=verbose_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T06:07:32.276595Z",
     "start_time": "2019-07-17T06:07:31.680650Z"
    }
   },
   "outputs": [],
   "source": [
    "prod_desc_cat = pd.read_pickle('../data/processed/prod_desc_cat.pkl')\n",
    "#search_prod_levels =pd.read_pickle('../data/processed/search_prod_levels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU_ID</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>302087889</td>\n",
       "      <td>Lighting&gt;Sconces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301688935</td>\n",
       "      <td>Lighting&gt;Sconces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206788920</td>\n",
       "      <td>Lighting&gt;Sconces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>302087892</td>\n",
       "      <td>Lighting&gt;Sconces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302087891</td>\n",
       "      <td>Lighting&gt;Sconces</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SKU_ID          Category\n",
       "0  302087889  Lighting>Sconces\n",
       "1  301688935  Lighting>Sconces\n",
       "2  206788920  Lighting>Sconces\n",
       "3  302087892  Lighting>Sconces\n",
       "4  302087891  Lighting>Sconces"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextVectorizer:\n",
    "    def __init__(self, data=None, cols_to_filter=None):\n",
    "        \n",
    "        self.cols_to_filter = cols_to_filter\n",
    "        self.data = data\n",
    "        self.was_fit = False\n",
    "        self.stop_words = \n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        '''Preprocess Text'''\n",
    "        \n",
    "       #tokenize\n",
    "        tokens = text.apply(nlp)\n",
    "        \n",
    "        #\n",
    "        \n",
    "        \n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def add_stopword():\n",
    "        return \n",
    "    \n",
    "    \n",
    "    def \n",
    "    \n",
    "    \n",
    "    def vectorize(self, text):\n",
    "        '''\n",
    "        Vectorize text into tokens \n",
    "        '''\n",
    "        \n",
    "        return text_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T06:07:44.813620Z",
     "start_time": "2019-07-17T06:07:44.800550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU_ID</th>\n",
       "      <th>Product_name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Department</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>L5</th>\n",
       "      <th>L6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202524817</td>\n",
       "      <td>8 in. x 4 in. x 16 in. Concrete Solid Block</td>\n",
       "      <td>This 8 in. x 4 in. x 16 in. Solid Concrete Blo...</td>\n",
       "      <td>Non-Decor</td>\n",
       "      <td>Building Materials</td>\n",
       "      <td>Concrete, Cement &amp; Masonry</td>\n",
       "      <td>Concrete Blocks &amp; Bricks</td>\n",
       "      <td>Cinder Blocks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301169855</td>\n",
       "      <td>Hummingbird Stencil</td>\n",
       "      <td>This easy-to-use Hummingbird Stencil from Sten...</td>\n",
       "      <td>Non-Decor</td>\n",
       "      <td>Home Decor</td>\n",
       "      <td>Wall Decor</td>\n",
       "      <td>Wall Stencils</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301169855</td>\n",
       "      <td>Hummingbird Stencil</td>\n",
       "      <td>This easy-to-use Hummingbird Stencil from Sten...</td>\n",
       "      <td>Non-Decor</td>\n",
       "      <td>Paint</td>\n",
       "      <td>Craft &amp; Art Supplies</td>\n",
       "      <td>Stencils</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SKU_ID                                 Product_name  \\\n",
       "0  202524817  8 in. x 4 in. x 16 in. Concrete Solid Block   \n",
       "1  301169855                          Hummingbird Stencil   \n",
       "2  301169855                          Hummingbird Stencil   \n",
       "\n",
       "                                         Description Department  \\\n",
       "0  This 8 in. x 4 in. x 16 in. Solid Concrete Blo...  Non-Decor   \n",
       "1  This easy-to-use Hummingbird Stencil from Sten...  Non-Decor   \n",
       "2  This easy-to-use Hummingbird Stencil from Sten...  Non-Decor   \n",
       "\n",
       "                   L1                          L2                        L3  \\\n",
       "0  Building Materials  Concrete, Cement & Masonry  Concrete Blocks & Bricks   \n",
       "1          Home Decor                  Wall Decor             Wall Stencils   \n",
       "2               Paint        Craft & Art Supplies                  Stencils   \n",
       "\n",
       "              L4   L5   L6  \n",
       "0  Cinder Blocks  NaN  NaN  \n",
       "1            NaN  NaN  NaN  \n",
       "2            NaN  NaN  NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_desc_cat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_names = prod_desc_cat['Product_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_desc_cat['Product_name'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,\n",
    "                 variety=\"BrE\",\n",
    "                 user_abbrevs={},\n",
    "                 n_jobs=1):\n",
    "        \"\"\"\n",
    "        Text preprocessing transformer includes steps:\n",
    "            1. Text normalization\n",
    "            2. Punctuation removal\n",
    "            3. Stop words removal\n",
    "            4. Lemmatization\n",
    "        \n",
    "        variety - format of date (AmE - american type, BrE - british format) \n",
    "        user_abbrevs - dict of user abbreviations mappings (from normalise package)\n",
    "        n_jobs - parallel jobs to run\n",
    "        \"\"\"\n",
    "        self.variety = variety\n",
    "        self.user_abbrevs = user_abbrevs\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, *_):\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        partitions = 1\n",
    "        cores = mp.cpu_count()\n",
    "        if self.n_jobs <= -1:\n",
    "            partitions = cores\n",
    "        elif self.n_jobs <= 0:\n",
    "            return X_copy.apply(self._preprocess_text)\n",
    "        else:\n",
    "            partitions = min(self.n_jobs, cores)\n",
    "\n",
    "        data_split = np.array_split(X_copy, partitions)\n",
    "        pool = mp.Pool(cores)\n",
    "        data = pd.concat(pool.map(self._preprocess_part, data_split))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _preprocess_part(self, part):\n",
    "        return part.apply(self._preprocess_text)\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        normalized_text = self._normalize(text)\n",
    "        doc = nlp(normalized_text)\n",
    "        removed_punct = self._remove_punct(doc)\n",
    "        removed_stop_words = self._remove_stop_words(removed_punct)\n",
    "        return self._lemmatize(removed_stop_words)\n",
    "\n",
    "    def _normalize(self, text):\n",
    "        # some issues in normalise package\n",
    "        try:\n",
    "            return ' '.join(normalise(text, variety=self.variety, user_abbrevs=self.user_abbrevs, verbose=False))\n",
    "        except:\n",
    "            return text\n",
    "\n",
    "    def _remove_punct(self, doc):\n",
    "        return [t for t in doc if t.text not in string.punctuation]\n",
    "\n",
    "    def _remove_stop_words(self, doc):\n",
    "        return [t for t in doc if not t.is_stop]\n",
    "\n",
    "    def _lemmatize(self, doc):\n",
    "        return ' '.join([t.lemma_ for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, data=None,cols_to_filter=None):\n",
    "        \n",
    "        self.cols_to_filter = cols_to_filter\n",
    "        self.was_fit = False\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"learn any information from the training data we may need to transform the test data\"\"\"\n",
    "        \n",
    "        # learn from the training data and return the class itself. \n",
    "        # allows you to chain fit and predict methods like \n",
    "        \n",
    "        # > p = preprocessor()\n",
    "        # > p.fit(X).transform(X)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"transform the training or test data\"\"\"\n",
    "        # transform the training or test data based on class attributes learned in the `fit` step\n",
    "        return X_new\n",
    "    \n",
    "    def clean_text(doc_arr):\n",
    "        for doc in doc_arr:\n",
    "            yield(gensim.utils.simple_preprocess(doc))\n",
    "        \n",
    "        clean_names = list(clean_text(names))\n",
    "    \n",
    "    def add_stopword(self):\n",
    "        \n",
    "    def remove_stopwords(self):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:08:07.935058Z",
     "start_time": "2019-07-16T20:08:07.931768Z"
    }
   },
   "outputs": [],
   "source": [
    "names = prod_desc_cat['Product_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:08:14.679284Z",
     "start_time": "2019-07-16T20:08:08.704110Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(doc_arr):\n",
    "    for doc in doc_arr:\n",
    "        yield(gensim.utils.simple_preprocess(doc))\n",
    "        \n",
    "clean_names = list(clean_text(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:08:21.451697Z",
     "start_time": "2019-07-16T20:08:21.447669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define List of Stop Words\n",
    "new_stop_words = ['in', 'sq','ft', 'yd', 'cm', 'mm','gal','lb' ,'lbs','qt','oz', 'h', 'w', 'ii', 'x']\n",
    "\n",
    "stop_words = set(stopwords.words('english') + new_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:08:32.670687Z",
     "start_time": "2019-07-16T20:08:32.141478Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove Stopwords\n",
    "def remove_stopwords(tokens, stop_words=stop_words):\n",
    "    return [token for token in tokens if not token in stop_words]\n",
    "    \n",
    "clean_names = list(map(remove_stopwords, clean_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Bigram/Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:10:08.020337Z",
     "start_time": "2019-07-16T20:09:28.777094Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jaime/miniconda3/envs/thddecor/lib/python3.7/site-packages/gensim/models/phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete solid block \n",
      "\n",
      "hummingbird stencil \n",
      "\n",
      "hummingbird stencil \n",
      "\n",
      "acrylic clear white dry_erase_board \n",
      "\n",
      "clear white boom dry_erase_board \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(clean_names, min_count=25)\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[clean_names], min_count=15) \n",
    "\n",
    "# Names as a trigram/bigram\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_model = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "#View Results\n",
    "for name in clean_names[0:5]:\n",
    "    print(f'{\" \".join(trigram_model[bigram_model[name]]) } \\n')\n",
    "          \n",
    "# Update document (names)\n",
    "          \n",
    "clean_names = [trigram_model[bigram_model[name]] for name in clean_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Search Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:44:52.766335Z",
     "start_time": "2019-07-16T20:44:52.750192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search_term</th>\n",
       "      <th>Display_name</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>L3</th>\n",
       "      <th>L4</th>\n",
       "      <th>L5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accent table</td>\n",
       "      <td>Entryway Tables</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Entryway Furniture</td>\n",
       "      <td>Entryway Tables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accent table</td>\n",
       "      <td>End Tables</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Living Room Furniture</td>\n",
       "      <td>Accent Tables</td>\n",
       "      <td>End Tables</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accent table</td>\n",
       "      <td>Coffee Tables</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Living Room Furniture</td>\n",
       "      <td>Accent Tables</td>\n",
       "      <td>Coffee Tables</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accent table</td>\n",
       "      <td>Console Tables</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Living Room Furniture</td>\n",
       "      <td>Accent Tables</td>\n",
       "      <td>Console Tables</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accent table</td>\n",
       "      <td>Indoor Plant Stands</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Living Room Furniture</td>\n",
       "      <td>Accent Tables</td>\n",
       "      <td>Indoor Plant Stands</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Search_term         Display_name         L1                     L2  \\\n",
       "0  accent table      Entryway Tables  Furniture     Entryway Furniture   \n",
       "1  accent table           End Tables  Furniture  Living Room Furniture   \n",
       "2  accent table        Coffee Tables  Furniture  Living Room Furniture   \n",
       "3  accent table       Console Tables  Furniture  Living Room Furniture   \n",
       "4  accent table  Indoor Plant Stands  Furniture  Living Room Furniture   \n",
       "\n",
       "                L3                   L4   L5  \n",
       "0  Entryway Tables                  NaN  NaN  \n",
       "1    Accent Tables           End Tables  NaN  \n",
       "2    Accent Tables        Coffee Tables  NaN  \n",
       "3    Accent Tables       Console Tables  NaN  \n",
       "4    Accent Tables  Indoor Plant Stands  NaN  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_prod_levels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:46:59.465551Z",
     "start_time": "2019-07-16T20:46:59.461063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make array\n",
    "search_terms = search_prod_levels['Search_term'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:47:17.292148Z",
     "start_time": "2019-07-16T20:47:17.280781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean Text\n",
    "clean_queries = list(clean_text(search_terms))\n",
    "\n",
    "# Remove Stopwords\n",
    "def remove_stopwords(tokens, stop_words=stop_words):\n",
    "    return [token for token in tokens if not token in stop_words]\n",
    "    \n",
    "clean_queries = list(map(remove_stopwords, clean_queries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T21:00:15.585780Z",
     "start_time": "2019-07-16T21:00:12.331261Z"
    }
   },
   "outputs": [],
   "source": [
    "#Make names df\n",
    "names_df= prod_desc_cat.loc[:, ['SKU_ID','Product_name']]\n",
    "names_df.set_index('Product_name', inplace=True)\n",
    "names_df['clean_names'] = clean_names\n",
    "names_df['clean_names'] = names_df['clean_names'].str.join(' ')\n",
    "\n",
    "\n",
    "#Make queries df\n",
    "queries_df = search_prod_levels.loc[:, ['Search_term']]\n",
    "queries_df['clean_queries'] = clean_queries\n",
    "queries_df = queries_df.drop_duplicates('Search_term')\n",
    "queries_df.set_index('Search_term', inplace=True)\n",
    "queries_df['clean_queries'] = queries_df['clean_queries'].str.join(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T21:00:31.022546Z",
     "start_time": "2019-07-16T21:00:21.417756Z"
    }
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words=stop_words)\n",
    "tfidf_matrix_names = tf.fit_transform(names_df['clean_names'])\n",
    "tfidf_matrix_queries = tf.fit_transform(queries_df['clean_queries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-16T21:07:55.425Z"
    }
   },
   "outputs": [],
   "source": [
    "#Cosine similarity\n",
    "cosine_similarities = linear_kernel(tfidf_matrix_names, tfidf_matrix_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(names_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T21:07:45.336989Z",
     "start_time": "2019-07-16T21:06:06.381Z"
    }
   },
   "outputs": [],
   "source": [
    "def recommendations(name, cosine_similarities = cosine_similarities):\n",
    "    \n",
    "    recommended_products = []\n",
    "    \n",
    "    # gettin the index of the hotel that matches the name\n",
    "    idx = indices[indices == name].index[0]\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar hotels except itself\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    # populating the list with the names of the top 10 matching hotels\n",
    "    for i in top_10_indexes:\n",
    "        recommended_products.append(list(df.index)[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Preprocessor Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessor:\n",
    "    def __init__(self, cols_to_filter=None):\n",
    "        \n",
    "        self.cols_to_filter = cols_to_filter\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"learn any information from the training data we may need to transform the test data\"\"\"\n",
    "        \n",
    "        # learn from the training data and return the class itself. \n",
    "        # allows you to chain fit and predict methods like \n",
    "        \n",
    "        # > p = preprocessor()\n",
    "        # > p.fit(X).transform(X)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"transform the training or test data\"\"\"\n",
    "        # transform the training or test data based on class attributes learned in the `fit` step\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Imputation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Description Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thddecor]",
   "language": "python",
   "name": "conda-env-thddecor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
